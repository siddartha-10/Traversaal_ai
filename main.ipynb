{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents import create_csv_agent\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "load_dotenv()\n",
    "import pandas as pd\n",
    "from langchain_community.document_loaders import JSONLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(openai_api_version=os.environ.get(\"AZURE_OPENAI_VERSION\", \"2023-07-01-preview\"),\n",
    "        azure_deployment=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt4chat\"),\n",
    "        azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"https://gpt-4-trails.openai.azure.com/\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '/Users/siddartha/Desktop/github/Traversaal_ai/data.json', 'seq_num': 1, 'location': 'Istanbul', 'price_range': 'low'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def metadata_func(record: str, metadata: dict) -> dict:\n",
    "    lines = record.split('\\n')\n",
    "    locality_line = lines[10]\n",
    "    price_range_line = lines[12]\n",
    "    locality = locality_line.split(': ')[1]\n",
    "    price_range = price_range_line.split(': ')[1]\n",
    "    metadata[\"location\"] = locality\n",
    "    metadata[\"price_range\"] = price_range\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# Instantiate the JSONLoader with the metadata_func\n",
    "jq_schema = '.parser[] | to_entries | map(\"\\(.key): \\(.value)\") | join(\"\\n\")'\n",
    "loader = JSONLoader(\n",
    "    jq_schema=jq_schema,\n",
    "    file_path='data.json',\n",
    "    metadata_func=metadata_func,\n",
    ")\n",
    "\n",
    "# Load the JSON file and extract metadata\n",
    "documents = loader.load()\n",
    "\n",
    "# Print the metadata of the first document\n",
    "print(documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(type(documents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [i.page_content for i in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    openai_api_version=os.environ.get(\"AZURE_OPENAI_VERSION\", \"2023-07-01-preview\"),\n",
    "    azure_deployment=os.environ.get(\"embeddings\",\"embed\"),\n",
    "    azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"https://gpt-4-trails.openai.azure.com/\"),\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "def get_vectorstore(text_chunks):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(documents=text_chunks, embedding=embeddings)\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = get_vectorstore(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "template = \"\"\"\n",
    "\n",
    "context:- I have low budget what is the best hotel in Instanbul?\n",
    "anser:- The other hotels in instanbul are costly and are not in your budget. so the best hotel in instanbul for you is hotel is xyz.\n",
    "\n",
    "\n",
    "Donâ€™t give information not mentioned in the CONTEXT INFORMATION. \n",
    "The system should take into account various factors such as location, amenities, user reviews, and other relevant criteria to \n",
    "generate informative and personalized explanations.\n",
    "{context}\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    " \n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector.as_retriever(),\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering your budget and the hotel reviews, the best hotel for you in Istanbul would be the Mula Hotel. It is reasonably priced and has received excellent reviews from guests, with a rating value of 5 from 197 reviews. It is located in the heart of the city, close to popular historical attractions like the Blue Mosque, Hagia Sophia, and the Topkapi Palace. Guests have praised the hotel's intimate atmosphere, modern architecture, serene ambiance, and the breathtaking views of the Sea of Marmara. [Here is the link to the hotel.](https://www.tripadvisor.com/Hotel_Review-g293974-d24067960-Reviews-or30-Mula_Hotel-Istanbul.html)\n"
     ]
    }
   ],
   "source": [
    "response = chain.run(\"I have low budget what is the best hotel in Instanbul?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Wyndham Grand Istanbul Kalamis Marina Hotel is near a water body. Located in Istanbul, Turkiye, this hotel is situated on the Fener Kalamis Caddesi. The hotel has a high rating of 4.5 and offers amenities such as anti-allergic and disabled rooms.\n"
     ]
    }
   ],
   "source": [
    "response = chain.run(\"Give me a hotel that is near a water body?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.http.models import Batch\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text):\n",
    "    response = openai.Embedding.create(inputs=text)\n",
    "    return response['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (0.24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
      "Requirement already satisfied: exceptiongroup in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.1.1)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (0.17.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai.api'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIApi\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Define a query vector\u001b[39;00m\n\u001b[1;32m      3\u001b[0m query_vector \u001b[38;5;241m=\u001b[39m encode_text(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery text\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai.api'"
     ]
    }
   ],
   "source": [
    "from openai.api import OpenAIApi\n",
    "# Define a query vector\n",
    "query_vector = encode_text(\"query text\")\n",
    "\n",
    "# Retrieve relevant documents based on the query vector\n",
    "relevant_documents = qdrant.get_relevant_documents(query_vector)\n",
    "\n",
    "# Use OpenAI's language model to generate answers based on the retrieved documents\n",
    "# Example: Use the retrieved documents as context for a language model completion\n",
    "response = OpenAIApi().complete(\n",
    "    model=\"text-davinci-003\",\n",
    "    documents=relevant_documents,\n",
    "    prompt=\"Generate an answer based on the retrieved documents.\"\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
